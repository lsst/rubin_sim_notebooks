{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6e8bc5",
   "metadata": {},
   "source": [
    "# Test Code for the Galactic Plane Footprint Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27fc6e",
   "metadata": {},
   "source": [
    "Code adapted from an example by Lynne Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c082d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import rubin_sim.maf as maf\n",
    "from rubin_sim.data import get_data_dir\n",
    "import healpy as hp\n",
    "from astropy import units as u\n",
    "from astropy_healpix import HEALPix\n",
    "from astropy.coordinates import Galactic, TETE, SkyCoord\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc4ce3",
   "metadata": {},
   "source": [
    "Load the baseline v2.0 as a test case OpSim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b928dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rstreet1/rubin_sim_data/sim_baseline/baseline_v2.0_10yrs.db\n",
      "baseline_v2.0_10yrs\n"
     ]
    }
   ],
   "source": [
    "from rubin_sim.data import get_baseline\n",
    "\n",
    "opsim_fname = get_baseline()\n",
    "print(opsim_fname)\n",
    "\n",
    "runName = os.path.split(opsim_fname)[-1].replace('.db', '')\n",
    "print(runName)\n",
    "opsim_db = maf.OpsimDatabase(opsim_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c48d5",
   "metadata": {},
   "source": [
    "Taking an example sky location within the Galactic Bulge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df2fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ra = (17.0 + 57.0/60.0 + 34.0/3600.0)*15.0\n",
    "test_dec = (29.0 + 13.0/60.0 + 15.0/3600.0)*-1.0\n",
    "test_slicer = maf.UserPointsSlicer(test_ra, test_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce6fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_map_data(file_path):\n",
    "\n",
    "    with fits.open(file_path) as hdul:\n",
    "        map_data_table = hdul[1].data\n",
    "\n",
    "    return map_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ffbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class galPlaneFootprintMetric(maf.BaseMetric):\n",
    "    \"\"\"Metric to evaluate the survey overlap with desired regions in the Galactic Plane\n",
    "    and Magellanic Clouds, by referencing the pre-computed priority maps provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fieldRA : float, RA in degrees of a given pointing\n",
    "    fieldDec : float, Dec in degrees of a given pointing\n",
    "    filter : str, filter bandpass used for a given observation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cols=[\"fieldRA\", \"fieldDec\", \"filter\", \"fiveSigmaDepth\"],\n",
    "        metricName=\"GalPlaneFootprintMetric\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Kwargs must contain:\n",
    "        filters  list Filterset over which to compute the metric\n",
    "        \"\"\"\n",
    "\n",
    "        self.ra_col = \"fieldRA\"\n",
    "        self.dec_col = \"fieldDec\"\n",
    "        self.filterCol = \"filter\"\n",
    "        self.m5Col = \"fiveSigmaDepth\"\n",
    "        self.filters = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "        self.magCuts = {\n",
    "            \"u\": 22.7,\n",
    "            \"g\": 24.1,\n",
    "            \"r\": 23.7,\n",
    "            \"i\": 23.1,\n",
    "            \"z\": 22.2,\n",
    "            \"y\": 21.4,\n",
    "        }\n",
    "        cwd = os.getcwd()\n",
    "        self.MAP_DIR = get_data_dir()\n",
    "        self.MAP_FILE_ROOT_NAME = \"priority_GalPlane_footprint_map_data\"\n",
    "        self.load_maps()\n",
    "\n",
    "        super().__init__(col=cols, metricName=metricName, metricDtype=\"object\")\n",
    "\n",
    "    def load_maps(self):\n",
    "        self.NSIDE = 64\n",
    "        self.NPIX = hp.nside2npix(self.NSIDE)\n",
    "        self.ideal_combined_map = np.zeros(self.NPIX)\n",
    "        for f in self.filters:\n",
    "            file_path = os.path.join(\n",
    "                self.MAP_DIR,\n",
    "                \"maf\",\n",
    "                self.MAP_FILE_ROOT_NAME + \"_\" + str(f) + \".fits\",\n",
    "                )\n",
    "            map_data_table = load_map_data(file_path)\n",
    "\n",
    "            setattr(self, \"map_\" + str(f), map_data_table['combined_map'])\n",
    "            setattr(self, \"map_data_\" + str(f), map_data_table)\n",
    "            self.ideal_combined_map += map_data_table['combined_map']\n",
    "\n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "\n",
    "        # Initialize holding array for map pixels in the dataSlice that\n",
    "        # overlap with the desired survey area, summed over all filters\n",
    "        dataslice_map = np.zeros(self.NPIX)\n",
    "\n",
    "        for f in self.filters:\n",
    "            # Select from the dataSlice observations that meet the limiting magnitude\n",
    "            # requirements for the science concerned for this filter\n",
    "            idx1 = np.where(dataSlice[self.filterCol] == f)[0]\n",
    "            idx2 = np.where(dataSlice[self.m5Col] >= self.magCuts[f])[0]\n",
    "            match = list(set(idx1).intersection(set(idx2)))\n",
    "\n",
    "            # Calculate the ICRS coordinates of the observed fields and\n",
    "            # convert these to galactic coordinates\n",
    "            coords_icrs = SkyCoord(\n",
    "                dataSlice[self.ra_col][match],\n",
    "                dataSlice[self.dec_col][match],\n",
    "                frame=\"icrs\",\n",
    "                unit=(u.deg, u.deg),\n",
    "            )\n",
    "            coords_gal = coords_icrs.transform_to(Galactic())\n",
    "\n",
    "            # Calculate which HEALpixels in the sky map are covered by these\n",
    "            # observations\n",
    "            ahp = HEALPix(nside=self.NSIDE, order=\"ring\", frame=TETE())\n",
    "            pixels = ahp.skycoord_to_healpix(coords_gal)\n",
    "\n",
    "            # Add the priority values for these HEALpixels from the map of\n",
    "            # the desired footprint to the combined_map array\n",
    "            weighted_map = getattr(self, \"map_\" + str(f))\n",
    "            dataslice_map[pixels] += weighted_map[pixels]\n",
    "\n",
    "        # This loop computes the main metric value over all HEALpixels in the sky map\n",
    "        # (\"combined_map\") as well as over the HEALpixels of the specific regions\n",
    "        # of interest for different science cases\n",
    "        map_data = getattr(self, \"map_data_\" + str(f))\n",
    "        metric_data = {}\n",
    "\n",
    "        for col in map_data.columns:\n",
    "            \n",
    "            region_pixels = np.where(map_data[col.name] > 0.0)\n",
    "\n",
    "            # To return a single metric value for the whole map, sum the total\n",
    "            # priority of all desired pixels included in the survey observations:\n",
    "            metric = dataslice_map[region_pixels].sum()\n",
    "\n",
    "            # Normalize by full weighted map summed over all filters and pixels:\n",
    "            metric /= self.ideal_combined_map[region_pixels].sum()\n",
    "\n",
    "            metric_data[col.name] = metric\n",
    "            \n",
    "        return metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde11d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymetric = galPlaneFootprintMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a5be1",
   "metadata": {},
   "source": [
    "Constraints, if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd74bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlconstraint = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fac7d7",
   "metadata": {},
   "source": [
    "Construct the metric bundle from the metric, the slicer and the constraints, and add it to a bundle group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a74fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = maf.MetricBundle(mymetric, test_slicer, sqlconstraint, runName=runName)\n",
    "g = maf.MetricBundleGroup({'test_metric': bundle}, opsim_db, outDir='test', resultsDb=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608ab3d",
   "metadata": {},
   "source": [
    "Calculate the metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43aa7605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying database None with no constraint for columns ['rotSkyPos', 'fieldDec', 'fieldRA', 'fiveSigmaDepth', 'filter'].\n",
      "Found 2086980 visits\n",
      "Running:  ['test_metric']\n",
      "Completed metric generation.\n",
      "Running reduce methods.\n",
      "Running summary statistics.\n",
      "Completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/rk7n9jss74g3shm9z6msmyvh0000gp/T/ipykernel_5490/1538269111.py:106: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  metric /= self.ideal_combined_map[region_pixels].sum()\n"
     ]
    }
   ],
   "source": [
    "g.runAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f7c73e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[{'combined_map': 0.003087635890244705, 'galactic_plane_map': 0.003381995315272647, 'magellenic_clouds_map': 0.0, 'galactic_bulge_map': 0.7772022292620246, 'clementini_stellarpops_map': nan, 'bonito_sfr_map': 0.0, 'globular_clusters_map': 0.03468437679624619, 'open_clusters_map': 0.006380251482250282, 'zucker_sfr_map': 0.0, 'pencilbeams_map': 0.050007083596832834, 'xrb_priority_map': 0.003087635890244705}],\n",
       "             mask=[False],\n",
       "       fill_value=-666,\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle.metricValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2071c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
