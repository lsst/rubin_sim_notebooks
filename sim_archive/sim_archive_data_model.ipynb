{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6724b538",
   "metadata": {},
   "source": [
    "# The Rubin Scheduler Simulation Archive Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee37cb",
   "metadata": {},
   "source": [
    "## Visits\n",
    "\n",
    "**This databases is not intended to store metadata on individual visits, but rather sequences of visits.**\n",
    "\n",
    "If there are use ever cases where an application is frequently querying small subets of sets of visits, maybe we can consider adding a table of visits. But, for our present use cases, storing the visit metedata in separate files in an S3 bucket is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81217fc",
   "metadata": {},
   "source": [
    "## Visit sequences\n",
    "\n",
    "- The name \"visit sequence\" is provisional: I'm looking for a better option.\n",
    "- \"visit sequence\" is a table of visit metadata that can be read by `rubin_sim.maf.get_sim_data` or `rubin_scheduler.scheduler.utils.SchemaConverter.opsim2obs`.\n",
    "    - Documentation I can find is out of date: https://lsst-sims.github.io/sims_ocs/tables/summaryallprops.html\n",
    "- Presently saved as sqlite3 data files\n",
    "    - I propose supporting hdf5 files as well (or even instead).\n",
    "        - More standardized and portable.\n",
    "        - For `baseline_v4.3_10yrs`, the `sqlite3` file is 719M, local read takes 25s.\n",
    "        - In `hdf5` (uncompressed), the file is 695M, local read takes 2.2s.\n",
    "          - `hdf5` has optional built-in compression which shrinks the size of the file at the expense of read and write times. If the download from the S3 bucket is the bottleneck rather than the read into python itself, maybe experimenting with a non-0 compression level would be useful.\n",
    "        - Whether we do this is not important for the purposes of this metadata database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386f521",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Contents of visit sequence files\n",
    "\n",
    "Pre-night and progress simulations will typically be completed after pre-loading a set of completed visits.\n",
    "There is an important question of whether to include the pre-loaded visits in visit sequences placed into the archive, or to limit the rows in the visit table in the archive to newly simulated visits.\n",
    "Limiting the saved visits to newly simulated visits has several advantages:\n",
    "1. The pre-night report only uses visits from one night, and this is always one of the newly simulated nights. The pre-night simulation presently simulate three nights, so including the pre-loaded visits would increase the archive space, bandwith used, and time spent downloading data by a factor 1/3 of the nights we are into the survey. For example, less 10 months into the survey, the visit sequence would be 100 times larger than necessary if previous visits are included.\n",
    "2. Averaged over all timesteps, half of all visits in the simulation used for one time sample in progress reports are completed visits. If the completed visits are retrieved only once, storing only the simulated visits will reduce the size of the visit downloads by a factor of two.\n",
    "The cost of this efficience is the additional complexity of requiring the client to combine the simulated visits with the parent visits whenever the complete set is needed. This complexity can be hidden in the client, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0630ce5",
   "metadata": {},
   "source": [
    "## `simulations` table\n",
    "\n",
    "Tracks output of opsim simulations, primarily those generated for the pre-night briefing and progress tracking, but baselines might also be useful to include.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY UNIQUE | RFC 4122 Universally Unique IDentifier (from python's `uuid.uuid4()`)|\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| tags | JSONB | json array of tags. Recent versions of postgresql support querying inside json arrays |\n",
    "| creation_time | TIMESTAMP WITH TIME ZONE NOT NULL| when the simulation was run |\n",
    "| scheduler_version | TEXT | version of `rubin_scheduler` |\n",
    "| config_repo | TEXT | git repo with configuration |\n",
    "| config_version | TEXT | revision of git repo with configuration |\n",
    "| config_script | TEXT | path of script in git repo that provides the configuation |\n",
    "| config_sha256 | BYTEA | hash of config_script |\n",
    "| sim_runner_args | JSONB | arguments to sim runner as a json dict |\n",
    "| rewards_url | TEXT | URL of rewards hdf5 file |\n",
    "| scheduler_url | TEXT | URL of pickle of scheduler |\n",
    "| conda_env_sha256 | BYTEA | SHA256 hash of output of `conda list --json` |\n",
    "| host | TEXT | host on which the simulation was run |\n",
    "| parent_visitseq_uuid | UUID | UUID of visitseq loaded into scheduler before running |\n",
    "| parent_last_day_obs | DATE | day_obs of last visit loaded into scheduler before running |\n",
    "\n",
    "In principle, `config_repo`, `config_version`, and `config_script` should be enough to exactly specify the config file used. However, `config_sha256` is still useful for identifying when the config script did not change across config repository versions, or for identifying config scripts that were not taken from a git repository (in which case the `config_repo` etc. would be `NULL`.)\n",
    "\n",
    "PostgreSQL has a native json type that can be used in queries, so we can, for example, query for simulations with a given value of `sim_start_mjd` or `n_visit_limit` using the `sim_runner_args` column in this table.\n",
    "\n",
    "RFC 4122 UUIDs can be generated with the python standard library with `uuid.uuid4()`. These should be generated by whatever process is inserting new data into the table.\n",
    "\n",
    "SHA-256 is a fast hash function that python can apply to recarrays, and is stable across versions of python (unlike python's `hash`). If we compute the SHA-256 for the `recarray` representation of the visit table, we can detect if we ever fail to reconstruct it exactly. This code fragment shows how this might be computed:\n",
    "```\n",
    "import hashlib\n",
    "visitseq_hash = hashlib.sha256(str(recs.dtype).encode())\n",
    "visitseq_hash.update(np.ascontiguousarray(recs).data.tobytes())\n",
    "hex_digest = visitset_hash.hexdigest()\n",
    "```\n",
    "To insert it into a BYTEA column in postgresql:\n",
    "```\n",
    "sql = f\"INSERT INTO obstable (visitshash) VALUES (decode('{hex_higest}', 'hex'))\"\n",
    "```\n",
    "\n",
    "This would, of course, be handled transparently by the python client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f442b04",
   "metadata": {},
   "source": [
    "## `completed` table\n",
    "\n",
    "Tracks results of visit sequences representing actually compleded visits, primarily (probably entirely) derived from queries to the consdb.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY | RFC 4122 Universally Unique IDentifier |\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL| \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| tags | JSONB | json array of tags. Recent versions of postgresql support querying inside json arrays |\n",
    "| creation_time | TIMESTAMP WITH TIME ZONE | when the consdb was queried |\n",
    "| query | TEXT | The query to the consdb used |\n",
    "\n",
    "Inclusion of the first and last day obs will let us save incremental updates.\n",
    "\n",
    "Inclusion of the query will let us select subsets (e.g., just one band), but may not be necessary.\n",
    "\n",
    "We might sometimes want to create entries in this table with the `visitseq_url` set to `NULL`, if we want to record statistics for a set of visits queried from the consdb and want to record how we got them, but do not need to save the visits themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa41a19",
   "metadata": {},
   "source": [
    "## `mixedvisitseqs` table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1099fd1",
   "metadata": {},
   "source": [
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY | RFC 4122 Universally Unique IDentifier |\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| tags | JSONB | json array of tags. Recent versions of postgresql support querying inside json arrays |\n",
    "| last_early_day_obs | DATE | the last day obs drawn from the early parent |\n",
    "| first_late_day_obs | DATE | the first day obs drawn from the late parent |\n",
    "| early_parent_uuid | UUID | the UUID of the early parent |\n",
    "| late_parent_uuid | UUID | the UUID of the late parent |\n",
    "\n",
    "Note that a client can recover the visit sequence even if the `visitseq_url` column is `NULL` if the early and late parents can be retrieved by querying the early parent for visits between `first_day_obs` and `last_early_day_obs` and the late parent for visits between `first_late_day_obs` and `last_day_obs` and concatenating the results.\n",
    "\n",
    "I don't know if it's a good idea, but `mixedvisitseqs` visit sequences can in principle be daisy-chained: the parent uuids can themselves refer to other entries in the `mixedvisitseqs` table, allowing for the specification of visit sequences comprised of any number of fragments of other visit sequences. This might be useful as a mechanism for incremental updates to queries of the consdb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b197894",
   "metadata": {},
   "source": [
    "## `visitseq` table\n",
    "\n",
    "The `simulations`, `completed`, and `mixedvisitseqs` tables all have several fields in common, and we may wish to query a table where we don't have to deal with each separately, for example which joining the parent UUID columns in the `mixedvisitseqs` table to its parents. We could accomplish this with a view, but a better way would be to take advantage of postgresql's inheritence: we can create a parent table with the columns that `simulations`, `completed`, and `mixedvisitseqs` have in common:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY | RFC 4122 Universally Unique IDentifier |\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| tags | JSONB | json array of tags. Recent versions of postgresql support querying inside json arrays |\n",
    "\n",
    "Queries to this table will see rows from all of its children: `simulations`, `completed`, and `mixedvisitseqs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5cfca5",
   "metadata": {},
   "source": [
    "## `visitseqstats` table\n",
    "\n",
    "Statistics of the distributions of visit parameters or values of MAF metrics can be included in the database, for example to make progress plots.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID REFERENCES visitseq(visiteseq_uuid) | RFC 4122 Universally Unique IDentifier |\n",
    "| first_dayobs | DATE | The day obs of the first night included in statistics (NULL if all) |\n",
    "| last_dayobs | DATE | The day obs of the last night included in statistics (NULL if all) |\n",
    "| band | TEXT | band of visits included or on which metric is measured (NULL if all) |\n",
    "| name | TEXT | metric or parameter name |\n",
    "| rubin_sim_version | TEXT | version of rubin_sim used to calculate the metric (NULL if not a rubin_sim metric)|\n",
    "| count | INTEGER | number of values in distribution |\n",
    "| mean | DOUBLE PRECISION | mean value of metric |\n",
    "| std | DOUBLE PRECISION | standard deviation of metric |\n",
    "| min | DOUBLE PRECISION | min value of metric |\n",
    "| p05 | DOUBLE PRECISION | 5% quantile of metric distribution |\n",
    "| q1 | DOUBLE PRECISION | first quartile of metric distribution |\n",
    "| median | DOUBLE PRECISION | median of metric |\n",
    "| q3 | DOUBLE PRECISION | third quartile of metric distribution |\n",
    "| p95 | DOUBLE PRECISION | 95% quantile of metric distribution |\n",
    "| max | DOUBLE PRECISION | maximum value of metric |\n",
    "\n",
    "The `first_dayobs`, `last_dayobs`, and `band` columns can be used to indicate a subset of visits included in the statistics.\n",
    "\n",
    "For example, a pre-night briefing simulation should have rows in this table where `first_dayobs == last_dayobs` and `name == 'slewDistance'` for each night of teh simulation, so a user (e.g. the night synopsis tool) can query the database for the count of visits and rough distribution of slew distances for each night simulated. Other good candidates for visit parameters which might be included are `airmass`, `fiveSigmaDepth`, and `moonDistance`.\n",
    "\n",
    "MAF metrics can also be stored. For example, the distribution of g band 5-sigma depths of healpixels at dayobs `2028-04-01` might be found in a row with `last_dayobs = '2028-04-01'`, `band = 'g'`, and `name = 'coaddM5 HealpixSlicer'`. These values can be used to make progress plots for the progress reports.\n",
    "\n",
    "If we wanted even more extensive `maf` support, we could add these columns, but **I don't see a need for this now, and they could be added later if needed**:\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| constraint | TEXT | constraint imposed in maf |\n",
    "| metric_class_name | TEXT | class name of the metric |\n",
    "| metric_args | JSONB | arguments to the metric constructor |\n",
    "| slicer_class_name | TEXT | class name of the slicer |\n",
    "| slicer_args | JSONB | arguments to the slicer constructor |\n",
    "\n",
    "These would all be `NULL` for non-MAF parameter statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc06b1f",
   "metadata": {},
   "source": [
    "## `condaenv` (maybe)\n",
    "\n",
    "While in many cases saving conda environments will probably not be useful, there may be times when it is, and we can save environments in a separate table.\n",
    "The simplest thing would be to just store the output of `conda list --json` in a table:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| conda_env_hash | BYTEA PRIMARY KEY | SHA256 hash of output of `conda list --json` |\n",
    "| conda_env | JSONB NOT NULL | output of `conda list --json` |\n",
    "\n",
    "The content of the output of `conda list --json` is a list of dictionaries, and postgreSQL would be able to query the contents more efficiently if the keys of these dicts were mapped to columns in a table:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| conda_env_hash | BYTEA NOT NULL | SHA256 hash of output of `conda list --json` |\n",
    "| base_url | TEXT NOT NULL |  |\n",
    "| build_number |  INTEGER NOT NULL | | \n",
    "| build_string | TEXT NOT NULL | |\n",
    "| channel | TEXT NOT NULL | |\n",
    "| dist_name | TEXT NOT NULL | |\n",
    "| name | TEXT NOT NULL | |\n",
    "| platform | TEXT NOT NULL | |\n",
    "| version | TEXT NOT NULL | |\n",
    "\n",
    "The first form would be easy to set up and use, and more robust with respect to changes in conda if it ever changed its schema for its output json file.\n",
    "The second form would support more efficient querying with postgresql and be more closely aligned with database best practices.\n",
    "\n",
    "We need not require that all environments used be included in this table. For example, saving the detailed environments for the prenight simulations is unlikely to be useful and will take a lot of space, so we should just skip adding these environments to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee22a69",
   "metadata": {},
   "source": [
    "## Thoughts on presistence\n",
    "\n",
    "Many of the simulations will be of only transient interest, and will not warrent keeping around for ever. We may, however, want to keep their records in this database around even after the visit sequence data itself has been deleted. We can indicate this by setting the URLs in the various tables to `NULL`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad41136",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Most of the simulations to be included in this archive will be handled by automated processes, but there should also be `python` and command line APIs to add \"hand-generated\" simulations or metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156d419",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
