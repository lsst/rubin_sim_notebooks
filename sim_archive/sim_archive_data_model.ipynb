{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6724b538",
   "metadata": {},
   "source": [
    "# The Rubin Scheduler Simulation Archive Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee37cb",
   "metadata": {},
   "source": [
    "## Scope\n",
    "### Visits\n",
    "\n",
    "**This databases is not intended to store metadata on individual visits, but rather sequences of visits.**\n",
    "\n",
    "If there are use ever cases where an application is frequently querying small subets of sets of visits, maybe we can consider adding a table of visits. But, for our present use cases, storing the visit metedata in separate files in an S3 bucket is better.\n",
    "\n",
    "### Included data\n",
    "\n",
    "The primary intention of this database is to track the plethora of simulations automatically produced to support the monitoring and progress reports (e.g. the prenight briefing). A few other simulations needed for these reports (e.g. the current baseline) will probably also be included, but initially it is not intended to include most simulations done for strategy evaluation, or even most simulations made \"by hand\" for other reports. It might someday evolvue to replace summary metric data archive described [here](https://github.com/lsst/rubin_sim_notebooks/blob/main/maf/tutorial/04_Getting_Data.ipynb), and some ideas for that are described."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81217fc",
   "metadata": {},
   "source": [
    "## Visit sequences\n",
    "\n",
    "- The name \"visit sequence\" is provisional: I'm looking for a better option.\n",
    "- \"visit sequence\" is a table of visit metadata that can be read by `rubin_sim.maf.get_sim_data` or `rubin_scheduler.scheduler.utils.SchemaConverter.opsim2obs`.\n",
    "    - Documentation I can find is out of date: https://lsst-sims.github.io/sims_ocs/tables/summaryallprops.html\n",
    "- Presently saved as sqlite3 data files with legacy column names\n",
    "    - I propose supporting hdf5 files as well (or even instead).\n",
    "        - More standardized and portable.\n",
    "        - For `baseline_v4.3_10yrs`, the `sqlite3` file is 719M, local read takes 25s.\n",
    "        - In `hdf5` (uncompressed), the file is 695M, local read takes 2.2s.\n",
    "          - `hdf5` has optional built-in compression which shrinks the size of the file at the expense of read and write times. If the download from the S3 bucket is the bottleneck rather than the read into python itself, maybe experimenting with a non-0 compression level would be useful.\n",
    "        - Whether we do this is not important for the purposes of this metadata database.\n",
    "    - I propose using column names that match those used in `consdb`, when corresponding columns exist in the `consdb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386f521",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Contents of visit sequence files\n",
    "\n",
    "Pre-night and progress simulations will typically be completed after pre-loading a set of completed visits.\n",
    "There is an important question of whether to include the pre-loaded visits in visit sequences placed into the archive, or to limit the rows in the visit table in the archive to newly simulated visits.\n",
    "Limiting the saved visits to newly simulated visits has several advantages:\n",
    "1. The pre-night report only uses visits from one night, and this is always one of the newly simulated nights. The pre-night simulation presently simulate three nights, so including the pre-loaded visits would increase the archive space, bandwith used, and time spent downloading data by a factor 1/3 of the nights we are into the survey. For example, less 10 months into the survey, the visit sequence would be 100 times larger than necessary if previous visits are included.\n",
    "2. Averaged over all timesteps, half of all visits in the simulation used for one time sample in progress reports are completed visits. If the completed visits are retrieved only once, storing only the simulated visits will reduce the size of the visit downloads by a factor of two.\n",
    "The cost of this efficience is the additional complexity of requiring the client to combine the simulated visits with the parent visits whenever the complete set is needed. This complexity can be hidden in the client, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e8b4f",
   "metadata": {},
   "source": [
    "## Sample Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328e807",
   "metadata": {},
   "source": [
    "### Query the consdb and add the results to the archive\n",
    "\n",
    "To query the consdb, add them to an S3 bucket, and record that they are there in the archive database from within python:\n",
    "\n",
    "```\n",
    "from rubin_sim.visitsarch import VisitsSequenceArchive\n",
    "visit_seq_archive = VisitSequenceArchive()\n",
    "# query, endpoint, and archive keyword arguments will default to the values\n",
    "# shown below, but are explicity shown in this example to show where\n",
    "# they can be overridden, and indicate that other pre-defined values\n",
    "# might also be included as module-level variables in visitsarch.\n",
    "\n",
    "last_consdb_dayobs=20250820\n",
    "visits, completed_arch_id = visits_seq_archive.query_consdb(\n",
    "    query=visitsarch.SIMONYI_SCIENCE_CONSDB_QUERY,\n",
    "    label=\"Here is are same visits to the consdb.\",\n",
    "    telescope=\"simonyi\",\n",
    "    last_dayobs=last_consdb_dayobs,\n",
    "    endpoint=visitsarch.USDF_CONSDB\n",
    "    archive=visitsarch.USDF_OPSIM_ARCHIVE\n",
    ")\n",
    "```\n",
    "\n",
    "The same could by done in `bash`, putting the visits into an h5 file rather than returning them:\n",
    "\n",
    "```\n",
    "COMPLETED_ARCH_ID=$(visitsarch query_consdb \\\n",
    "    completed_visits.h5, \n",
    "    --label=\"Here is another set of sample visits\",\n",
    "    --telescope=\"simonyi\",\n",
    "    --last_dayobs=20360101,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278b9df",
   "metadata": {},
   "source": [
    "### Run a simulation and add it to the archive\n",
    "\n",
    "When running a simulation in python, either with stand-alone python executable or in a jupyter notebook, the process will look like this:\n",
    "\n",
    "```\n",
    "from rubin_sim.visitsarch import VisitsSequenceArchive\n",
    "visit_seq_archive = VisitSequenceArchive()\n",
    "\n",
    "# Get the completed visits following the previous use case, then update the scheduler:\n",
    "scheduler.add_observations(SchemaConverter().opsim2obs(completed_visits))\n",
    "\n",
    "# Run the simulation\n",
    "sim_runner_kwargs = {\n",
    "    'observatory': observatory,\n",
    "    'scheduler': scheduler,\n",
    "    'band_scheduler': band_scheduler,\n",
    "    'sim_start_mjd': sim_start,\n",
    "    'sim_duration': sim_end-sim_start,\n",
    "    'keep_rewards': True}\n",
    "observatory, scheduler, obs, rewards, obs_rewards = sim_runner(**sim_runner_kwargs)\n",
    "\n",
    "# Create the entry in the simulations table and copy the visits to the S3 archive:\n",
    "arch_id = visit_seq_archive.add_simulation(\n",
    "    visits=obs,\n",
    "    label=\"This is my example simulation.\",\n",
    "    telescope=\"simonyi\",\n",
    "    first_day_obs=sim_start,\n",
    "    last_day_obs=sim_end,\n",
    "    scheduler_version=rubin_scheduler.__version__,\n",
    "    config_url=\"https://raw.githubusercontent.com/lsst-ts/ts_config_ocs/8ed1ab/Scheduler/feature_scheduler/maintel/fbs_config_sv_survey.py\",\n",
    "    sim_runner_args=sim_runner_kwargs,\n",
    "    parent_visitseq_uuid=completed_arch_id, ;# See previous use case example\n",
    "    parent_last_dayobs=last_consdb_dayobs, ;# See previous use case example\n",
    ")\n",
    "\n",
    "# Add appropriate tags:\n",
    "visits_seq_archive.tag(arch_id, ['example', 'nominal'])\n",
    "\n",
    "# Save the python environment:\n",
    "visits_seq_archive.save_env(arch_id)\n",
    "\n",
    "# Save the rewards and pickles of important objects to the S3 bucket,\n",
    "# and record what and where they are in the database\n",
    "visit_seq_archive.add_file(arch_id, 'rewards', [rewards, obs_rewards])\n",
    "visit_seq_archive.add_file(arch_id, 'scheduler', scheduler)\n",
    "visit_seq_archive.add_ifle(arch_id, 'observatory', observatory)\n",
    "```\n",
    "\n",
    "Alternately, we could do it in `bash` with files:\n",
    "\n",
    "```\n",
    "# Run the simulation, saving visits and rewards to h5 files and scheduler and observatory objects to pickles,\n",
    "# then:\n",
    "\n",
    "ARCHID=$(visitsarch add_simulation \\\n",
    "    --label=\"This is my bash example simulation\" \\\n",
    "    --telescope=\"simonyi\",\n",
    "    --config_url=\"\"https://raw.githubusercontent.com/lsst-ts/ts_config_ocs/8ed1ab/Scheduler/feature_scheduler/maintel/fbs_config_sv_survey.py\" \\\n",
    ")\n",
    "\n",
    "visitsarch tag $ARCHID example nominal\n",
    "visitsarch save_env $ARCHID\n",
    "visitsarch add_file $ARCHID rewards rewards.h5\n",
    "visitsarch add_file $ARCHID scheduler scheduler.p\n",
    "visitsarch add_file $ARCHID observatory observatory.p\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f9d62",
   "metadata": {},
   "source": [
    "### Query the simulation archive for simulations\n",
    "\n",
    "Any of the tables and views descibed below can be queried with SQL, and return `pandas.DataFrames` (in python) or delimited text (in bash).\n",
    "Direct use of `pd.read_sql` will often be perfectly reasonable, but a helper that creates and drops the connection might be used, for example:\n",
    "\n",
    "```\n",
    "from rubin_sim.visitsarch import VisitsSequenceArchive\n",
    "visit_seq_archive = VisitSequenceArchive()\n",
    "all_tagged_prenight_df = visit_seq_archive.query(\"SELECT * FROM visitsextra WHERE tags ? 'mytest1'\")\n",
    "```\n",
    "Note the use of the non-standard `postresql` operator `?` which when applied to a json object (as `tags` is in the `visitsextra` view) tests whether a string is a member of a json sequence.\n",
    "\n",
    "The corresponding command in bash would be:\n",
    "\n",
    "```\n",
    "visitarch query \"SELECT \\* FROM visitsextra WHERE tags \\? 'mytest1'\" > mytesttable.txt\n",
    "```\n",
    "\n",
    "In addition, there should be a handful of commands that explicitly implement common use cases.\n",
    "For example, to retrieve a table of pre-night simulations for a give night, in python:\n",
    "```\n",
    "day_obs = 20250814\n",
    "prenight_for_night = visitsarch.prenight_sims(day_obs)\n",
    "```\n",
    "or, in bash:\n",
    "```\n",
    "visitsarch prenight_sim 20250814\n",
    "```\n",
    "\n",
    "These would return tables of simulations suitable for building a pre-night simulation, with all the metadata needed for selecing a simulation from which to make a pre-night briefing, and then obtaining the necessary data (`visitseq_uuid`, `label`, `telescope`, `creation_time`, `parent_last_day_obs`, and URLs for the visits and rewards)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcf38f",
   "metadata": {},
   "source": [
    "### Getting data from the archive\n",
    "\n",
    "Once the `visitseq_uuid` of interest is discovered through querying the `simulations` or `completed` tables or the `visitsextra` view, the actual visit, reward, or other data should be downloadable from the buckets pointed to.\n",
    "\n",
    "For example, in python:\n",
    "```\n",
    "from rubin_sim.visitsarch import VisitSequenceArchive\n",
    "visit_seq_archive = VisitsSequenceArchive()\n",
    "visits = visit_seq_archive.download(visitseq_uuid, 'visits')\n",
    "rewards, obs_rewards = visits_seq_archive.download(visitseq_uuid, 'rewards')\n",
    "scheduler = visits__seq_archive.download(visitseq_uuid, 'scheduler')\n",
    "```\n",
    "or, in bash:\n",
    "```\n",
    "visitsarch download $ARCHID visits visits.h5\n",
    "visitsarch download $ARCHID rewards rewards.h5\n",
    "visitsarch.download $ARCHID scheduler scheduler.p\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb316cef",
   "metadata": {},
   "source": [
    "## Tables in the visit sequence metadata database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0630ce5",
   "metadata": {},
   "source": [
    "### `simulations` table\n",
    "\n",
    "Tracks output of opsim simulations, primarily those generated for the pre-night briefing and progress tracking, but baselines might also be useful to include.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY UNIQUE | RFC 4122 Universally Unique IDentifier (from python's `uuid.uuid4()`)|\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| visitseq_label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5). It can be NULL, so statistics etc. can be stored in the database even if the actual visits are never saved. |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| creation_time | TIMESTAMP WITH TIME ZONE NOT NULL| when the simulation was run |\n",
    "| scheduler_version | TEXT | version of `rubin_scheduler` |\n",
    "| config_url | TEXT | URL for the config script, e.g. https://raw.githubusercontent.com/lsst-ts/ts_config_ocs/${COMMIT_HASH}/Scheduler/feature_scheduler/maintel/fbs_config_sv_survey.py |\n",
    "| sim_runner_args | JSONB | arguments to sim runner as a json dict |\n",
    "| conda_env_sha256 | BYTEA | SHA256 hash of output of `conda list --json` |\n",
    "| parent_visitseq_uuid | UUID | UUID of visitseq loaded into scheduler before running |\n",
    "| parent_last_day_obs | DATE | day_obs of last visit loaded into scheduler before running |\n",
    "\n",
    "In principle, `config_repo`, `config_version`, and `config_script` should be enough to exactly specify the config file used. However, `config_sha256` is still useful for identifying when the config script did not change across config repository versions, or for identifying config scripts that were not taken from a git repository (in which case the `config_repo` etc. would be `NULL`.)\n",
    "\n",
    "PostgreSQL has a native json type that can be used in queries, so we can, for example, query for simulations with a given value of `sim_start_mjd` or `n_visit_limit` using the `sim_runner_args` column in this table.\n",
    "\n",
    "RFC 4122 UUIDs can be generated with the python standard library with `uuid.uuid4()`. These should be generated by whatever process is inserting new data into the table.\n",
    "\n",
    "SHA-256 is a fast hash function that python can apply to recarrays, and is stable across versions of python (unlike python's `hash`). If we compute the SHA-256 for the `recarray` representation of the visit table, we can detect if we ever fail to reconstruct it exactly. This code fragment shows how this might be computed:\n",
    "```\n",
    "import hashlib\n",
    "visitseq_hash = hashlib.sha256(str(recs.dtype).encode())\n",
    "visitseq_hash.update(np.ascontiguousarray(recs).data.tobytes())\n",
    "hex_digest = visitseq_hash.hexdigest()\n",
    "```\n",
    "To insert it into a BYTEA column in postgresql:\n",
    "```\n",
    "sql = f\"INSERT INTO obstable (visitshash) VALUES (decode('{hex_higest}', 'hex'))\"\n",
    "```\n",
    "\n",
    "This would, of course, be handled transparently by the python client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f442b04",
   "metadata": {},
   "source": [
    "## `completed` table\n",
    "\n",
    "Tracks results of visit sequences representing actually compleded visits, primarily (probably entirely) derived from queries to the consdb.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY | RFC 4122 Universally Unique IDentifier |\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| visitseq_label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL| \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| creation_time | TIMESTAMP WITH TIME ZONE | when the consdb was queried |\n",
    "| query | TEXT | The query to the consdb used |\n",
    "\n",
    "Inclusion of the first and last day obs will let us save incremental updates.\n",
    "\n",
    "Inclusion of the query will let us select subsets (e.g., just one band), but may not be necessary.\n",
    "\n",
    "We might sometimes want to create entries in this table with the `visitseq_url` set to `NULL`, if we want to record statistics for a set of visits queried from the consdb and want to record how we got them, but do not need to save the visits themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa41a19",
   "metadata": {},
   "source": [
    "## `mixedvisitseqs` table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1099fd1",
   "metadata": {},
   "source": [
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY | RFC 4122 Universally Unique IDentifier |\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| visitseq_label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| creation_time | TIMESTAMP WITH TIME ZONE | date when sequence was defined |\n",
    "| last_early_day_obs | DATE | the last day obs drawn from the early parent |\n",
    "| first_late_day_obs | DATE | the first day obs drawn from the late parent |\n",
    "| early_parent_uuid | UUID | the UUID of the early parent |\n",
    "| late_parent_uuid | UUID | the UUID of the late parent |\n",
    "\n",
    "Note that a client can recover the visit sequence even if the `visitseq_url` column is `NULL` if the early and late parents can be retrieved by querying the early parent for visits between `first_day_obs` and `last_early_day_obs` and the late parent for visits between `first_late_day_obs` and `last_day_obs` and concatenating the results.\n",
    "\n",
    "I don't know if it's a good idea, but `mixedvisitseqs` visit sequences can in principle be daisy-chained: the parent uuids can themselves refer to other entries in the `mixedvisitseqs` table, allowing for the specification of visit sequences comprised of any number of fragments of other visit sequences. This might be useful as a mechanism for incremental updates to queries of the consdb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b197894",
   "metadata": {},
   "source": [
    "## `visitseq` table\n",
    "\n",
    "The `simulations`, `completed`, and `mixedvisitseqs` tables all have several fields in common, and we may wish to query a table where we don't have to deal with each separately, for example which joining the parent UUID columns in the `mixedvisitseqs` table to its parents. We could accomplish this with a view, but a better way would be to take advantage of postgresql's inheritence: we can create a parent table with the columns that `simulations`, `completed`, and `mixedvisitseqs` have in common:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY | RFC 4122 Universally Unique IDentifier |\n",
    "| visitseq_sha256 | BYTEA NOT NULL | hash of visit table |\n",
    "| visitseq_label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5) |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| creation_time | TIMESTAMP WITH TIMES ZONE | date when sequence was created |\n",
    "\n",
    "Queries to this table will see rows from all of its children: `simulations`, `completed`, and `mixedvisitseqs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7feb7d2",
   "metadata": {},
   "source": [
    "## `tags`\n",
    "\n",
    "Visit sequences can be marked with tags.\n",
    "Any given visit sequence can have any number of tags, and any given tag can apply to any number of visit sequences.\n",
    "Tags will typically be short strings without spaces, and used to retrieve subsets of visit sequences in an automatic way.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID | SHA256 hash of output of `conda list --json` |\n",
    "| tag | TEXT NOT NULL | A tag for the visit sequence |\n",
    "\n",
    "Note that tags can be used to serve the same function as \"run families\" are used in the `rubin_sim.maf.run_comparison` submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba063072",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## `comments`\n",
    "\n",
    "Comments can be added to visit sequences.\n",
    "Any given visit sequence can have any number of comments.\n",
    "Comments are intended to be free-form text to be interpreted by humans.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID| SHA256 hash of output of `conda list --json` |\n",
    "| comment_time | TIME STAMP WITH TIME ZONE | The date and time at which the comment was added |\n",
    "| author | TEXT | The user who added the comment |\n",
    "| comment | TEXT NOT NULL | A tag for the visit sequence |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f86e9",
   "metadata": {},
   "source": [
    "## `files`\n",
    "\n",
    "The `files` table saves references to files that are associated with a given set of visits.\n",
    "Typical examples include `rewards` (for recorded rewards) and `scheduler` (a pickle of the scheduler instance), and `observatory` (a pickle of the observatory).\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID | RFC 4122 Universally Unique IDentifier |\n",
    "| file_type | TEXT NOT NULL | Examples include \"rewards\", \"scheduler\", and \"observatory\" |\n",
    "| file_sha256 | BYTEA NOT NULL | hash of the file |\n",
    "| file_url | text | URL for the file |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbf3c6",
   "metadata": {},
   "source": [
    "`simulations_extra` view\n",
    "\n",
    "The `visitsextra` includes simulation column with extra columns with tags, comments, and files aggregated into json.\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID PRIMARY KEY UNIQUE | RFC 4122 Universally Unique IDentifier (from python's `uuid.uuid4()`)|\n",
    "| visitseq_label | TEXT NOT NULL | label for plots and tables |\n",
    "| visitseq_url | TEXT | URL of visit sequence (sqlite3, maybe hdf5). It can be NULL, so statistics etc. can be stored in the database even if the actual visits are never saved. |\n",
    "| telescope | TEXT NOT NULL | \"simonyi\" or \"auxtel\" |\n",
    "| first_day_obs | DATE NOT NULL | day obs of first visit in sequence |\n",
    "| last_day_obs | DATE NOT NULL | day obs of last visit in sequence |\n",
    "| creation_time | TIMESTAMP WITH TIME ZONE NOT NULL| when the simulation was run |\n",
    "| scheduler_version | TEXT | version of `rubin_scheduler` |\n",
    "| config_url | TEXT | URL for the config script, e.g. https://raw.githubusercontent.com/lsst-ts/ts_config_ocs/${COMMIT_HASH}/Scheduler/feature_scheduler/maintel/fbs_config_sv_survey.py |\n",
    "| sim_runner_args | JSONB | arguments to sim runner as a json dict |\n",
    "| conda_env_sha256 | BYTEA | SHA256 hash of output of `conda list --json` |\n",
    "| parent_visitseq_uuid | UUID | UUID of visitseq loaded into scheduler before running |\n",
    "| parent_last_day_obs | DATE | day_obs of last visit loaded into scheduler before running |\n",
    "| tags | JSONB | the set of tags on the simulation |\n",
    "| comments | JSONB | the mapping of times to comments on the simulation |\n",
    "| files | JSONB | the mapping of file type to URL on the simulation |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc06b1f",
   "metadata": {},
   "source": [
    "## `condaenv`\n",
    "\n",
    "While in many cases saving conda environments will probably not be useful, there may be times when it is, and we can save environments in a separate table.\n",
    "The simplest thing would be to just store the output of `conda list --json` in a table:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| conda_env_hash | BYTEA PRIMARY KEY | SHA256 hash of output of `conda list --json` |\n",
    "| conda_env | JSONB NOT NULL | output of `conda list --json` |\n",
    "\n",
    "We need not require that all environments used be included in this table. For example, saving the detailed environments for the prenight simulations is unlikely to be useful and will take a lot of space, so we should just skip adding these environments to this table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5cfca5",
   "metadata": {},
   "source": [
    "## `nightly_stats` table\n",
    "\n",
    "Statistics of the distributions of visit parameters or other values can be included in the database.\n",
    "\n",
    "The particular statistits are chosen to support the creation of [box-and-whisker plots](https://en.wikipedia.org/wiki/Box_plot).\n",
    "\n",
    "For a given sequence of visits, the rows to add to this table might be generated thus:\n",
    "```\n",
    "columns = ['s_ra', 's_dec', 'sky_rotation', 'azimuth', 'altitude', 'eff_time_median', 'sky_bg_median', 'psf_area_median']\n",
    "vs_data = visits.groupby('day_obs')[columns].describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]).stack(level=0).reset_index()\n",
    "vs_data['accumulated'] = False\n",
    "```\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID  | RFC 4122 Universally Unique IDentifier |\n",
    "| day_obs | DATE | The day obs of the visits included |\n",
    "| value_name | TEXT | metric or column name |\n",
    "| accumulated | BOOLEAN | Whether the statistics include all data through night day_obs, or only data on night day_obs |\n",
    "| count | INTEGER | number of values in distribution |\n",
    "| mean | DOUBLE PRECISION | mean value of metric |\n",
    "| std | DOUBLE PRECISION | standard deviation of metric |\n",
    "| min | DOUBLE PRECISION | min value of metric |\n",
    "| p05 | DOUBLE PRECISION | 5% quantile of metric distribution |\n",
    "| q1 | DOUBLE PRECISION | first quartile of metric distribution |\n",
    "| median | DOUBLE PRECISION | median of metric |\n",
    "| q3 | DOUBLE PRECISION | third quartile of metric distribution |\n",
    "| p95 | DOUBLE PRECISION | 95% quantile of metric distribution |\n",
    "| max | DOUBLE PRECISION | maximum value of metric |\n",
    "\n",
    "Statistics will not be computed for all visit sequences, and not all avaliable values will be included for sequences that are included.\n",
    "\n",
    "Distributions of `maf` metrics could alse be added.\n",
    "For example, the `mean`, `std`, `min`, etc. could be the `mean` etc. of the values of healpixels for a maf metric made with a `HealpixSlicer` and returns a healpy array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d5ad6",
   "metadata": {},
   "source": [
    "## `maf_metrics` table\n",
    "\n",
    "**The need for this table is currently speculative.**\n",
    "\n",
    "If we wanted even more extensive `maf` support than supplied by the `nightlystats` table above, we could create a child table, `mafstats`, that inherets the colmuns from `nightlystats` and adds the following:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| maf_metric_name | TEXT PRIMARY KEY | A name for the MAF metric |\n",
    "| rubin_sim_version | TEXT | the version of rubin_sim used |\n",
    "| constraint | TEXT | constraint imposed in maf |\n",
    "| metric_class_name | TEXT | class name of the metric |\n",
    "| metric_args | JSONB | arguments to the metric constructor |\n",
    "| slicer_class_name | TEXT | class name of the slicer |\n",
    "| slicer_args | JSONB | arguments to the slicer constructor |\n",
    "\n",
    "This would support, for example, the creation of box-and-whisker plots of things like area with accumulated depth at different times during the survey, and support tracing exactly how these were computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea837d",
   "metadata": {},
   "source": [
    "## `maf_summary_metrics` table\n",
    "\n",
    "**The need for this table is currently speculative.**\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID | RFC 4122 Universally Unique IDentifier |\n",
    "| maf_metric_name | TEXT REFERENCES maf_stats(maf_metric_name) | The name for the maf metric |\n",
    "| day_obs | DATE | The last day_obs of visits included |\n",
    "| accumulated | BOOLEAN | true of all visits through day_obs are included, false if only visits on day_obs are |\n",
    "| summary_value | DOUBLE PRECISION | the value of the summary metric |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b67b1",
   "metadata": {},
   "source": [
    "## `maf_metric_sets` table\n",
    "\n",
    "**The need for this table is currently speculative.**\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| metric_set| TEXT NOT NULL | A name for the metric set |\n",
    "| maf_metric_name | TEXT REFERENCES maf_stats(maf_metric_name) | the MAF metric name|\n",
    "| short_name | TEXT | a shorter label to use in plots |\n",
    "| style | TEXT | matplotlib line style |\n",
    "| invert | BOOLEAN DEFAULT FALSE | lower is better? |\n",
    "| mag | BOOLEAN DEFAULT FALSE | value is a magnitude? |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1778936",
   "metadata": {},
   "source": [
    "## `maf_summary` view\n",
    "\n",
    "**The need for view is currently speculative.**\n",
    "\n",
    "A view can make it easy to get values and plotting style for all summary metrics in a given metric set,\n",
    "for runs with a given tag:\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| metric_set| TEXT NOT NULL | A name for the metric set |\n",
    "| maf_metric_name | TEXT REFERENCES maf_stats(maf_metric_name) | the MAF metric name |\n",
    "| visitseq_uuid | UUID | RFC 4122 Universally Unique IDentifier for the visit sequence |\n",
    "| visitseq_label | TEXT | Visit sequences label |\n",
    "| day_obs | DATE | The last day_obs of visits included |\n",
    "| accumulated | BOOLEAN | frue of all visits through day_obs are included, false if only visits on day_obs are |\n",
    "| summary_value | DOUBLE PRECISION | the value of the summary metric |\n",
    "| short_name | TEXT | a shorter label to use in plots |\n",
    "| style | TEXT | matplotlib line style |\n",
    "| invert | BOOLEAN DEFAULT FALSE | lower is better? |\n",
    "| mag | DOUBLE PRECISION | value is a magnitude? |\n",
    "| tag | TEXT | tag for the run |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47554e20",
   "metadata": {},
   "source": [
    "## `maf_healpix_stats` table\n",
    "\n",
    "**The need for this table is currently speculative.**\n",
    "\n",
    "| column | type | description |\n",
    "| --- | --- | --- |\n",
    "| visitseq_uuid | UUID | RFC 4122 Universally Unique IDentifier |\n",
    "| maf_metric_name | TEXT REFERENCES maf_stats(maf_metric_name) | The name for the maf metric |\n",
    "| day_obs | DATE | The last day_obs of visits included |\n",
    "| accumulated | BOOLEAN | frue of all visits through day_obs are included, false if only visits on day_obs are |\n",
    "| nside | INTEGER NOT NULL | the nside of the healpix map used |\n",
    "| count | INTEGER | number of unmasked values in distribution |\n",
    "| mean | DOUBLE PRECISION | mean value of metric |\n",
    "| std | DOUBLE PRECISION | standard deviation of metric |\n",
    "| min | DOUBLE PRECISION | min value of metric |\n",
    "| p05 | DOUBLE PRECISION | 5% quantile of metric distribution |\n",
    "| q1 | DOUBLE PRECISION | first quartile of metric distribution |\n",
    "| median | DOUBLE PRECISION | median of metric |\n",
    "| q3 | DOUBLE PRECISION | third quartile of metric distribution |\n",
    "| p95 | DOUBLE PRECISION | 95% quantile of metric distribution |\n",
    "| max | DOUBLE PRECISION | maximum value of metric |\n",
    "| url | TEXT | A url for the healpix values themselves, if saved |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee22a69",
   "metadata": {},
   "source": [
    "## Thoughts on presistence\n",
    "\n",
    "Many of the simulations will be of only transient interest, and will not warrent keeping around for ever. We may, however, want to keep their records in this database around even after the visit sequence data itself has been deleted. We can indicate this by setting the URLs in the various tables to `NULL`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad41136",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Most of the simulations to be included in this archive will be handled by automated processes, but there should also be `python` and command line APIs to add \"hand-generated\" simulations or metrics.\n",
    "\n",
    "The [`click`](https://click.palletsprojects.com/en/stable/) python module may be used to a command line app that has functions that correspond directly to the python API.\n",
    "\n",
    "Python functions will be supplied by the `rubin_sim.visitsarch` submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156d419",
   "metadata": {},
   "source": [
    "### Adding a simulation: `visitsarch add_simulation`\n",
    "\n",
    "The `visitsarch.add_simulation` function and `visitsarch add_simulation` bash command add a row to the `simulations` table, creating and returning an `visitseq_uuid` in the process.\n",
    "In addition, there will be an option to copy a set of visits into an archive (directory on disk on an S3 bucket).\n",
    "\n",
    "Required arguments:\n",
    "\n",
    "| argument | content |\n",
    "| --- | --- |\n",
    "| visits | Visits (in `pd.DataFrame` or `np.recarray`  in python, or name of an hdf5 file if bash) to add to archive |\n",
    "| label | Value for the \"label\" column in the `simulation` table |\n",
    "\n",
    "Optional arguments:\n",
    "\n",
    "An `archive` keyword argument (and corresponding `--archive` bash option) supplise the base URL for the archive in which to copy the visits.\n",
    "It can be `None` or an empty string if only a database entry should be created, and will fefaults to a standard S3 bucket.\n",
    "\n",
    "Some columns will always be computed automatically (`visitseq_uuid`, `visitseq_sha256`). \n",
    "Other columns can be set using keyword arguments (in python) or with the an `--` option to the bash command.\n",
    "In cases where it is possible, defaults should be created automatically. For example, `scheduler_version` can be derived automatically from the current environment, if it is not provided.\n",
    "\n",
    "python example:\n",
    "\n",
    "```\n",
    ">>> visits_id = visitsarch.add_simulation(\n",
    "...     visits,\n",
    "...     label=\"the visits I just simulted\",\n",
    "...     telescope=\"simonyi\",\n",
    "...     config_url=\"https://raw.githubusercontent.com/lsst-ts/ts_config_ocs/8ed1ab/Scheduler/feature_scheduler/maintel/fbs_config_sv_survey.py\",\n",
    "...     sim_runner_args=sim_runner_kwargs\n",
    "... )\n",
    "...\n",
    "```\n",
    "\n",
    "bash example:\n",
    "\n",
    "```\n",
    "$ visitsarch add_simulation visits.h5 \"the visits I just simulated\" \\\n",
    ">    --telescope=simonyi \\\n",
    ">    --config_url=https://raw.githubusercontent.com/lsst-ts/ts_config_ocs/8ed1ab/Scheduler/feature_scheduler/maintel/fbs_config_sv_survey.py\" \\\n",
    ">    --sim_running_kwargs=sim_runner_args.jsona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3903634",
   "metadata": {},
   "source": [
    "### Add visits from the `consdb`: `visitsarch query_consdb`\n",
    "\n",
    "Query the consdb, and add the returned visits as an entry in completed table.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "| argument | content |\n",
    "| --- | --- |\n",
    "| query | An sql query used to query the consdb |\n",
    "| label | Value for the \"label\" column in the `simulation` table |\n",
    "| telescope | \"simonyi\" or \"auxtel\" |\n",
    "| first_dayobs | dayobs before which there can be no visits. This might be eariler than the dayobs of the first visit, if there were no visits on the night of first_dayobs itself. |\n",
    "| last_dayobs | dayobs after which there can be no visits |\n",
    "| endpoint | The connection information for the consdb, defaulting to the USDF consdb |\n",
    "| archive | An endpoint in which to save the visit table. May be none, to simply record a metadata entry without saving the results. It should often be possible to recover the resuts of the query if it is not save just by sending the query again, but not if the consdb gets updated.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c8bdc",
   "metadata": {},
   "source": [
    "### Create a mixed set of visits: `visitsarch add_mixed`\n",
    "\n",
    "Create an entry in the `mixedvisitseqs` table.\n",
    "\n",
    "The `visitseq_uuid` and `visitseq_sha256` columns in the table will be determined automatically.\n",
    "\n",
    "`visitseq_url` can be optional: if the parents exist, the mixed sequence can be reconstructed.\n",
    "\n",
    "Other columns in the table require correspending arguments to `visitsarch add_mixed`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d71d3",
   "metadata": {},
   "source": [
    "### Add tags to a sequence of visits: `visitsarch tag`\n",
    "\n",
    "This can be simple.\n",
    "In python:\n",
    "```\n",
    "> visitsarch.tag(visitseq_id, ['tag1', 'tag2', 'tag3'])\n",
    "```\n",
    "\n",
    "or in bash:\n",
    "```\n",
    "$ visitsarch tag $VISITSEQID tag1 tag2 tag3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e579bd",
   "metadata": {},
   "source": [
    "### Add a comment to a sequence of visits: `visitsarch comment`\n",
    "\n",
    "This can be simple too.\n",
    "In python:\n",
    "```\n",
    "> visitsarch.comment(visitseq_id, \"This is more of a question that a comment...\")\n",
    "```\n",
    "\n",
    "or in bash:\n",
    "```\n",
    "$ visitsarch comment $VISITSEQID \"This is more of a question than a comment...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df174d54",
   "metadata": {},
   "source": [
    "### Save the current environment in the archive: `visitsarch save_env`\n",
    "\n",
    "No arguments are even needed, just use conda to get the environment.\n",
    "Note that the `visitsarch.add_simulation` command will already have added the hash of the environment for whatever simulations it applies to.\n",
    "This command merely saves what is actually in that environment.\n",
    "\n",
    "It python:\n",
    "```\n",
    "> visitsarch.save_env()\n",
    "```\n",
    "\n",
    "In bash:\n",
    "```\n",
    "$ visitsarch save_env\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb5faf",
   "metadata": {},
   "source": [
    "### Add files to the archive associated with a visit sequence: `visitsarch add_file`\n",
    "\n",
    "In python:\n",
    "\n",
    "```\n",
    "> base_url = \"s3://rubin:rubin-scheduler-prenight/opsim/\"\n",
    "> visitsarch.add_file(visits_id, \"rewards\", rewards_fname, archive=base_url)\n",
    "```\n",
    "\n",
    "In bash:\n",
    "\n",
    "```\n",
    "$ visitsarch add_file $VISITS_ID rewards myrewards.h5 s3://rubin:rubin-scheduler-prenight/opsim/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d184ae8",
   "metadata": {},
   "source": [
    "### Query for simulations for an instrument that cover a date: `visitsarch query_night`\n",
    "\n",
    "In python:\n",
    "\n",
    "```\n",
    "> visit_seqs = visitsarch.query_night(dayobs, telescope, earliest_sim, columns=['id', 'label', 'visitseq_url'], tags=['prenight', 'nominal'])\n",
    "```\n",
    "\n",
    "In bash:\n",
    "\n",
    "```\n",
    "$ visitsarch query_night 20250815 simonyi 2025-08-12 --columns id label visitseq_url --tags prenight nominal\n",
    "```\n",
    "\n",
    "Produces a `pandas.DataFrame` (python) or text table (bash) with columns requested, which could be anything from the `simulation`, `completed`, or `mixedvisitseqs` tables, plus `tags` (a list of tags from the `tags` table) and `comments` (a list of comments from the comments table).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d68c65",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehn313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
